{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9QQQM8V8HaI"
      },
      "outputs": [],
      "source": [
        "npm = 0  # TODO: Isi NPM Anda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpgRWdYt7Uq6"
      },
      "source": [
        "## 1. Prepare Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vRb9IA_8jt7",
        "outputId": "205e5ee4-3c25-45e5-b35f-6b0dc3250b63"
      },
      "outputs": [],
      "source": [
        "# Unduh dataset training dan testing\n",
        "!wget https://raw.githubusercontent.com/luthfibalaka/NLPL-Lab-4/refs/heads/main/train.csv\n",
        "!wget https://raw.githubusercontent.com/luthfibalaka/NLPL-Lab-4/refs/heads/main/test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zm-b7zWH7Uq7"
      },
      "outputs": [],
      "source": [
        "# Import packages yang relevan\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ivv_7Wz_7Uq8"
      },
      "outputs": [],
      "source": [
        "# Load dataset training dan testing\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Separasi antara teks yang digunakan dan label jenis berita\n",
        "texts = train_df['description'].values  # Bisa juga teks lain seperti title\n",
        "labels = train_df['news_type'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mCa5n1yn7Uq8"
      },
      "outputs": [],
      "source": [
        "# Jumlah kelas pada klasifikasi berdasarkan atribut news_type\n",
        "num_classes = train_df['news_type'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zsoSgkep7Uq9"
      },
      "outputs": [],
      "source": [
        "# Melatih dan melakukan tokenisasi pada teks\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AjcGKgS87Uq9"
      },
      "outputs": [],
      "source": [
        "# Melakukan padding teks sepanjang maksimal maxlen\n",
        "maxlen = 1000\n",
        "X_train = pad_sequences(sequences, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Rak1zvzJ7Uq9"
      },
      "outputs": [],
      "source": [
        "# Memecah data training untuk mendapatkan data validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, labels, test_size=0.2, random_state=npm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szDWmSHb7Uq9"
      },
      "source": [
        "## 2. Train and Test Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ylC-ZCCh7Uq-"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan model dan beberapa komponen terkait\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=8))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7LSP08k7Uq-",
        "outputId": "fd94cb73-91bc-4600-a32d-78a4b38d982f"
      },
      "outputs": [],
      "source": [
        "# Melatih model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s92F3qL67Uq-",
        "outputId": "711f4ada-3349-4db2-e101-14c7f084bbec"
      },
      "outputs": [],
      "source": [
        "# Menguji model pada data testing\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['description'].values)\n",
        "X_test = pad_sequences(test_sequences, maxlen=maxlen)\n",
        "y_test = test_df['news_type'].values\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
